# Transaction Analyzer Service

Service d'analyse et de catÃ©gorisation des transactions bancaires utilisant Llama 3 et FastAPI.

## ğŸ¯ FonctionnalitÃ©s

- CatÃ©gorisation automatique des transactions via Llama 3
- DÃ©tection des transactions rÃ©currentes
- Identification des patterns de dÃ©penses
- API RESTful avec documentation OpenAPI

## ğŸ›  PrÃ©requis

- Python 3.10+
- [Ollama](https://ollama.ai/) installÃ© localement
- Llama 3 tÃ©lÃ©chargÃ© via Ollama

## ğŸš€ Installation

1. Cloner le repository :
```bash
git clone https://github.com/yousmaaza/cashflow-analyzer-supabase.git
cd services/transaction-analyzer
```

2. CrÃ©er un environnement virtuel Python :
```bash
python -m venv .venv
source .venv/bin/activate  # Sur Windows : .venv\Scripts\activate
```

3. Installer les dÃ©pendances :
```bash
pip install -r requirements.txt
```

4. Installer et configurer Ollama avec Llama 3 :
```bash
# Installation d'Ollama (voir https://ollama.ai/download)

# TÃ©lÃ©chargement du modÃ¨le Llama 3
ollama pull llama3

# Configuration du contexte (optionnel)
ollama show --modelfile llama3 > modelfile
# Modifier num_ctx dans le modelfile si nÃ©cessaire
ollama create custom-llama3 -f modelfile
```

## ğŸ“ Configuration

1. CrÃ©er un fichier `.env` Ã  la racine du projet :
```env
# API Configuration
PORT=8000
ENVIRONMENT=development
LOG_LEVEL=DEBUG

# LLM Configuration
OLLAMA_HOST=http://localhost:11434
MODEL_NAME=llama3
```

## ğŸƒâ€â™‚ï¸ Lancement du service

1. DÃ©marrer le service en mode dÃ©veloppement :
```bash
uvicorn main:app --reload --port 8000
```

2. AccÃ©der Ã  :
   - API Documentation: http://localhost:8000/docs
   - API Alternative Doc: http://localhost:8000/redoc
   - Healthcheck: http://localhost:8000/

## ğŸ“Š Test du service

1. Exemple de requÃªte d'analyse de transactions :
```bash
curl -X POST "http://localhost:8000/api/v1/transactions/analyze" \
     -H "Content-Type: application/json" \
     -d '{
       "user_id": "user123",
       "transactions": [
         {
           "id": "tx1",
           "date": "2024-01-15",
           "description": "CARREFOUR MARKET",
           "amount": 42.50,
           "raw_text": "PAIEMENT CB CARREFOUR MARKET"
         }
       ]
     }'
```

## ğŸ§ª Tests

ExÃ©cuter les tests unitaires :
```bash
pytest
```

Avec couverture de code :
```bash
pytest --cov=app tests/
```

## ğŸ’¡ DÃ©veloppement

1. Structure du projet :
```
transaction-analyzer/
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ api/              # Routes FastAPI
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â””â”€â”€ routes.py    # Endpoints API
â”‚   â”œâ”€â”€ core/            # Configuration et utilitaires
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ config.py    # Configuration service
â”‚   â”‚   â””â”€â”€ logger.py    # Configuration logging
â”‚   â”œâ”€â”€ models/          # ModÃ¨les de donnÃ©es
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â””â”€â”€ schemas.py   # SchÃ©mas Pydantic
â”‚   â””â”€â”€ services/        # Logique mÃ©tier
â”‚       â”œâ”€â”€ __init__.py
â”‚       â”œâ”€â”€ llm_handler.py     # Gestion LLM
â”‚       â””â”€â”€ transaction_service.py  # Service principal
â”œâ”€â”€ tests/               # Tests unitaires
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ conftest.py     # Configuration pytest
â”‚   â”œâ”€â”€ test_api/       # Tests API
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â””â”€â”€ test_routes.py
â”‚   â”œâ”€â”€ test_services/  # Tests services
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ test_llm_handler.py
â”‚   â”‚   â””â”€â”€ test_transaction_service.py
â”‚   â””â”€â”€ test_models/    # Tests modÃ¨les
â”‚       â”œâ”€â”€ __init__.py
â”‚       â””â”€â”€ test_schemas.py
â”œâ”€â”€ .env                # Configuration locale
â”œâ”€â”€ .gitignore         # Fichiers ignorÃ©s par git
â”œâ”€â”€ main.py            # Point d'entrÃ©e de l'application
â”œâ”€â”€ requirements.txt    # DÃ©pendances Python
â””â”€â”€ README.md          # Documentation du projet
```

2. Guidelines dÃ©veloppement :
- Utiliser Black pour le formatage : `black app/`
- VÃ©rifier le lint : `flake8 app/`
- Organiser les imports : `isort app/`

## ğŸ¤ Contribution

1. CrÃ©er une nouvelle branche pour votre fonctionnalitÃ©
2. ImplÃ©menter vos changements
3. Ajouter des tests
4. Soumettre une Pull Request

## âš ï¸ Notes importantes

- Assurez-vous qu'Ollama est en cours d'exÃ©cution lors de l'utilisation du service
- Le modÃ¨le Llama 3 nÃ©cessite environ 4GB de RAM
- Le premier appel Ã  l'API peut Ãªtre lent dÃ» au chargement initial du modÃ¨le